// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
import {noteContent} from "./external-tokens.js"
export const parser = LRParser.deserialize({
  version: 14,
  states: "#YQQOPOOOVOPO'#C`O[OQO'#C_OOOO'#Ce'#CeQQOPOOOaOPO,58zOOOO,58y,58yOOOO-E6c-E6cOfOPO1G.fOnOPO7+$QOvOPO7+$QOOOQ<<Gl<<GlO{OPO<<GlO!QOPO<<GlOOOQAN=WAN=WO!YOPOAN=WOOOQG22rG22r",
  stateData: "!_~OZPO~O[TO~OPUO~OTWO~OUYOVXO~OW[OZZO~OV]O~OZ^O~OW_OZ^O~OZ`O~O",
  goto: "iYPPPZ_PPPPcTROSTQOSQSORVS",
  nodeNames: "âš  NoteContent Document Note NoteDelimiter NoteLanguage Auto BlockIdDelimiterMark BlockId",
  maxTerm: 12,
  skippedNodes: [0],
  repeatNodeCount: 1,
  tokenData: ".{~ReYZ!d}!O!i!Q![!t!]!^!|#V#W#_#W#X${#X#Y%n#Z#[&^#[#]'P#^#_'c#_#`(y#`#a)c#a#b){#d#e*z#f#g,f#g#h,u#h#i-_#j#k.^#l#m'V#m#n.d%&x%&y.j~!iOZ~~!lP#T#U!o~!tOU~~!yPW~!Q![!t~#PP!]!^#S~#VP!]!^#Y~#_OV~~#bR#`#a#k#d#e$`#g#h$f~#nP#c#d#q~#tP#^#_#w~#zP#i#j#}~$QP#f#g$T~$WP#X#Y$Z~$`OT~~$cP#d#e$Z~$iQ#[#]$o#g#h$Z~$rP#T#U$u~$xP#f#g$`~%OQ#T#U%U#]#^%b~%XP#f#g%[~%_P#h#i$Z~%eP#Y#Z%h~%kP#Y#Z$Z~%qP#f#g%t~%wP#`#a%z~%}P#T#U&Q~&TP#b#c&W~&ZP#Z#[$Z~&aQ#c#d%t#f#g&g~&jP#c#d&m~&pP#c#d&s~&vP#j#k&y~&|P#m#n$Z~'SP#h#i'V~'YP#a#b']~'`P#`#a$Z~'fQ#T#U'l#g#h(j~'oP#j#k'r~'uP#T#U'x~'}PT~#g#h(Q~(TP#V#W(W~(ZP#f#g(^~(aP#]#^(d~(gP#d#e%[~(mQ#c#d(s#l#m$Z~(vP#b#c$Z~(|P#c#d)P~)SP#h#i)V~)YP#`#a)]~)`P#]#^(s~)fP#X#Y)i~)lP#n#o)o~)rP#X#Y)u~)xP#f#g$Z~*OP#T#U*R~*UQ#f#g*[#h#i*t~*_P#_#`*b~*eP#W#X*h~*kP#c#d*n~*qP#k#l(s~*wP#[#]$Z~*}R#[#]$`#c#d+W#m#n,S~+ZP#k#l+^~+aP#X#Y+d~+gP#f#g+j~+mP#g#h+p~+sP#[#]+v~+yP#X#Y+|~,PP#`#a']~,VP#h#i,Y~,]P#[#],`~,cP#c#d(s~,iP#i#j,l~,oQ#U#V&y#g#h%[~,xR#[#]+v#e#f']#k#l-R~-UP#]#^-X~-[P#Y#Z%[~-bS#X#Y-n#c#d'V#g#h-t#m#n-z~-qP#l#m%[~-wP#l#m$Z~-}P#d#e.Q~.TP#X#Y.W~.ZP#g#h(Q~.aP#i#j$T~.gP#T#U'V~.mP%&x%&y.p~.sP%&x%&y.v~.{O[~",
  tokenizers: [0, noteContent],
  topRules: {"Document":[0,2]},
  tokenPrec: 0
})